# Big Data Lab Work Portfolio

This repo contains personal work portfolio for CMPT732-Big Data Lab 1. 

Mainly implementing data ETL to turn unstructured raw data into structured formats (csv, JSON, parquest, etc.), performing data analysis.

**Tools: Hadoop, PySpark (RDD, DataFrame, SQL), AWS (S3, RedShift, Spectrum, EMR), Cassandra, Kafka**\




- **Week 1**\
Tools: Apache Hadoop.

- **Week 2**\
Description: find out most-viewed Wikipedia pages using PySpark RDD.\

- **Week3**\
Description: Calculate Reddit average scores. \
             Estimate Euler's consant, e. \

- **Week 4**\
Description: Implement ETL on unstructured Reddit comment data, find out author with best comment by calculating relative scores for each comment.\
perform ETL on weather data.\

- **Week 5**\
Description: Implement previous data ETL work in AWS environmrnt.\

- **Week 6**\
Description: Find out most popular Wiki page by inferring date from filename.\
Find out weather station with the largest temperature difference by two methods: PySpark DataFrame and PySpark SQL.\

- **Week 7**\
Description: Find the shortest path in a graph.\
Calculate server log correlation with PySpark.\ 

- **Week 8**\
Description: Calculate server log correlation with Cassandra.

- **Week 9**\
Description: Query, analyze data using Redshift and Spectrum SQL from S3 datalake. 

- **Week 10**\
Description: Implement linear regression using streaming data.\
Color prediction, weather prediction with PySpark pipeline models. 

\
\
\
\
*Please don't copy code in this repository. All rights reserved.*
